---
title: "Graph Theory for Machine Learning"
subtitle: "Structure, Connection, and Meaning"
author: "EDA for Machine Learning"
format:
  revealjs:
    theme: [dark, eda4ml-slides.scss]
    slide-number: true
    toc: true
    toc-depth: 1
    toc-title: "Chapter 15"
    preview-links: auto
    progress: true
    hash: true
    incremental: false
    code-fold: true
    fig-width: 8
    fig-height: 5
execute:
  echo: false
  warning: false
  message: false
---

```{r}
#| label: CRAN-libraries

library(igraph)
library(tidyverse)

```

```{r}
#| label: local-libraries

library(eda4mldata)

```

```{r}
#| label: local-source

# Source helper functions
source(here::here("code", "learning_graph.R"))
source(here::here("code", "lg_diagnostics.R"))
source(here::here("code", "lg_schema.R"))

```

# The Nature of Graphs

## Networks Are Everywhere

Graphs appear whenever entities are connected:

- **Social networks**: People linked by friendship, collaboration, influence
- **Biological networks**: Proteins linked by interactions, genes by regulation
- **Information networks**: Web pages linked by hyperlinks, papers by citations
- **Knowledge graphs**: Concepts linked by semantic relationships

. . .

The mathematical abstraction—**nodes** and **edges**—unifies these diverse domains.

## Understanding and Prediction

Throughout this book we have seen that **understanding** and **decision support** are intertwined.

. . .

Graph analysis makes this especially vivid.

| Perspective | Question |
|-------------|----------|
| **Prediction** | Which nodes will connect next? What should we recommend? |
| **Understanding** | What communities exist? Who is influential? Why? |

. . .

These perspectives are complementary—structure enables prediction, and prediction reveals structure.

## The Questions Graphs Answer

**Structural questions** (understanding):

- What communities or clusters exist?
- Which nodes are central or influential?
- How does information or influence flow?

. . .

**Predictive questions** (decision support):

- Will these two nodes connect? (link prediction)
- What should this user see next? (recommendation)
- What's the shortest path from here to there? (routing)

## Three Examples

We explore graphs through three examples of increasing complexity:

| Example | Domain | Key Concepts |
|---------|--------|--------------|
| **Zachary's Karate Club** | Social network | Community detection, centrality |
| **MovieLens** | Recommendations | Bipartite graphs, projection |
| **LearningGraph** | Knowledge graph | Typed nodes, path queries, gap analysis |

. . .

Each illuminates different aspects of graph structure and different analytical questions.

# Example 1: Zachary's Karate Club

## The Story

In the 1970s, sociologist Wayne Zachary studied a university karate club.

. . .

A conflict arose between the instructor (Mr. Hi) and the club president (John A).

. . .

The club split. Zachary had recorded who interacted with whom *outside* the club.

. . .

**The question**: Could the social network predict which faction each member would join?

## The Network

```{r}
#| label: fig-karate-network
#| fig-cap: "Zachary's Karate Club network (34 members, 78 connections)"
#| fig-height: 5.5

karate <- igraph::make_graph("Zachary")

# Set up node attributes
igraph::V(karate)$name <- 1:igraph::vcount(karate)

# Known faction membership (ground truth)
# Mr. Hi's faction (node 1) vs John A's faction (node 34)
faction <- c(1,1,1,1,1,1,1,1,2,2,1,1,1,1,2,2,1,1,2,1,2,1,2,2,2,2,2,2,2,2,2,2,2,2)
igraph::V(karate)$faction <- faction
igraph::V(karate)$color <- ifelse(faction == 1, "#E41A1C", "#377EB8")

# Highlight the two leaders
igraph::V(karate)$size <- 15
igraph::V(karate)$size[1] <- 25   # Mr. Hi
igraph::V(karate)$size[34] <- 25  # John A

set.seed(42)
plot(karate, 
     layout = igraph::layout_with_fr(karate),
     vertex.label = igraph::V(karate)$name,
     vertex.label.color = "white",
     vertex.label.cex = 0.8,
     edge.color = "gray70",
     main = "")
legend("bottomleft", 
       legend = c("Mr. Hi's faction", "John A's faction"),
       fill = c("#E41A1C", "#377EB8"),
       bty = "n")
```

## What the Network Reveals

**Visual inspection** already suggests structure:

- Two dense regions with sparse connections between them
- Node 1 (Mr. Hi) and node 34 (John A) are hubs of their respective groups

. . .

**Zachary's result**: The network correctly predicted 33 of 34 members' choices.

. . .

The one "misclassified" member (node 9) had stronger ties to Mr. Hi's group but followed his close friend to John A's faction.

## Centrality: Who Matters?

**Degree centrality**: How many connections does a node have?

**Betweenness centrality**: How often does a node lie on shortest paths between others?

```{r}
#| label: fig-karate-centrality
#| fig-cap: "Karate Club with nodes sized by betweenness centrality"
#| fig-height: 4.5

betw <- igraph::betweenness(karate, normalized = TRUE)
igraph::V(karate)$size <- 10 + 40 * betw  # Scale for visibility

set.seed(42)
plot(karate,
     layout = igraph::layout_with_fr(karate),
     vertex.label = igraph::V(karate)$name,
     vertex.label.color = "white",
     vertex.label.cex = 0.7,
     edge.color = "gray70",
     main = "")
```

Node 1 (Mr. Hi) has highest betweenness—he's the bridge to many members.

## Community Detection

Can an algorithm recover the factions without knowing the ground truth?

```{r}
#| label: fig-karate-communities
#| fig-cap: "Communities detected by Louvain algorithm"
#| fig-height: 4.5

# Reset size
igraph::V(karate)$size <- 15
igraph::V(karate)$size[1] <- 25
igraph::V(karate)$size[34] <- 25

# Detect communities
comm <- igraph::cluster_louvain(karate)
igraph::V(karate)$color <- igraph::membership(comm)

set.seed(42)
plot(karate,
     layout = igraph::layout_with_fr(karate),
     vertex.label = igraph::V(karate)$name,
     vertex.label.color = "white",
     vertex.label.cex = 0.8,
     edge.color = "gray70",
     main = "")
```

The Louvain algorithm finds a partition very close to the actual split.

## Prediction Meets Understanding

The Karate Club illustrates the dual perspective:

. . .

**Understanding**: The network structure reveals social cohesion patterns. Communities exist because people preferentially associate with similar others.

. . .

**Prediction**: That same structure predicts future behavior. When forced to choose, people follow their network ties.

. . .

This is the power of graph analysis: **structure is predictive because structure reflects mechanism**.

# Example 2: MovieLens

## The Setting

MovieLens is a movie recommendation dataset from the GroupLens research lab.

. . .

**The data**: Users rate movies on a 1–5 scale.

. . .

**The question**: Given a user's rating history, what movies should we recommend?

## Bipartite Structure

```{r}
#| label: fig-movielens-bipartite
#| fig-cap: "A bipartite graph connecting users to the movies they rated."

# Sample users and movies for visualization
users <- paste0("U", 1:8)
movies <- c("Toy Story", "Pulp Fiction", "Forrest Gump", "Silence of the Lambs", 
            "Star Wars", "Schindler's List")

# Create edges (user-movie ratings)
edges <- tibble::tribble(
  ~user, ~movie,
  "U1", "Toy Story",
  "U1", "Star Wars",
  "U1", "Forrest Gump",
  "U2", "Pulp Fiction",
  "U2", "Forrest Gump",
  "U2", "Silence of the Lambs",
  "U3", "Toy Story",
  "U3", "Star Wars",
  "U4", "Pulp Fiction",
  "U4", "Schindler's List",
  "U5", "Toy Story",
  "U5", "Forrest Gump",
  "U5", "Star Wars",
  "U6", "Silence of the Lambs",
  "U6", "Schindler's List",
  "U7", "Star Wars",
  "U7", "Forrest Gump",
  "U8", "Pulp Fiction",
  "U8", "Silence of the Lambs"
)

# Build bipartite graph
g_bip <- igraph::graph_from_data_frame(edges, directed = FALSE)

# Set node types
igraph::V(g_bip)$type <- igraph::V(g_bip)$name %in% movies

# Layout: users on left, movies on right
coords <- matrix(0, nrow = igraph::vcount(g_bip), ncol = 2)
user_nodes <- which(!igraph::V(g_bip)$type)
movie_nodes <- which(igraph::V(g_bip)$type)

coords[user_nodes, 1] <- 0
coords[user_nodes, 2] <- seq(length(user_nodes), 1, length.out = length(user_nodes))
coords[movie_nodes, 1] <- 2
coords[movie_nodes, 2] <- seq(length(movie_nodes), 1, length.out = length(movie_nodes))

# Colors
igraph::V(g_bip)$color <- ifelse(igraph::V(g_bip)$type, "#377EB8", "#E41A1C")

plot(g_bip,
     layout = coords,
     vertex.size = 12,
     vertex.label.cex = 0.7,
     vertex.label.color = "black",
     vertex.label.dist = ifelse(igraph::V(g_bip)$type, 2.5, -2.5),
     edge.color = "gray70",
     main = "")
legend("bottom",
       legend = c("Users", "Movies"),
       fill = c("#E41A1C", "#377EB8"),
       horiz = TRUE,
       bty = "n")
```

Users and movies are **different types** of nodes. Edges connect users to movies they've rated.

## The Recommendation Question

**Collaborative filtering** idea: Users with similar taste will like similar movies.

. . .

Graph formulation:

- If User A and User B both rated Movie X highly...
- ...and User B also rated Movie Y highly...
- ...then recommend Movie Y to User A.

. . .

This is a **path query**: find movies reachable through similar users.

## Projection: User Similarity

We can "project" the bipartite graph onto users:

. . .

Two users are connected if they rated the same movie.  This projection enables standard graph algorithms on user similarity.

```{r}
#| label: fig-user-projection
#| fig-cap: "User projection: U1 and U2 both rated Forrest Gump (red), creating a projected edge (black)."
#| fig-width: 5
#| fig-height: 4
#| out-width: "70%"

# Minimal example for slide
movies_sm <- c("Toy Story", "Forrest Gump", "Pulp Fiction")

edges_sm <- tibble::tribble(
  ~user, ~movie,
  "U1", "Toy Story",
  "U1", "Forrest Gump",
  "U2", "Forrest Gump",
  "U2", "Pulp Fiction",
  "U3", "Toy Story",
  "U3", "Pulp Fiction"
)

g_bip2 <- igraph::graph_from_data_frame(edges_sm, directed = FALSE)
igraph::V(g_bip2)$type <- igraph::V(g_bip2)$name %in% movies_sm

# Add projected edge
g_bip2 <- igraph::add_edges(g_bip2, c("U1", "U2"))

# Edge styling
edge_list <- igraph::as_edgelist(g_bip2)
n_edges <- igraph::ecount(g_bip2)

edge_colors <- rep("gray70", n_edges)
edge_widths <- rep(1.5, n_edges)

for (i in 1:(n_edges - 1)) {
  e1 <- edge_list[i, 1]
  e2 <- edge_list[i, 2]
  is_u1_fg <- (e1 == "U1" & e2 == "Forrest Gump") | (e1 == "Forrest Gump" & e2 == "U1")
  is_u2_fg <- (e1 == "U2" & e2 == "Forrest Gump") | (e1 == "Forrest Gump" & e2 == "U2")
  if (is_u1_fg | is_u2_fg) {
    edge_colors[i] <- "#E74C3C"
    edge_widths[i] <- 3
  }
}

edge_colors[n_edges] <- "black"
edge_widths[n_edges] <- 3

# Node colors
igraph::V(g_bip2)$color <- ifelse(igraph::V(g_bip2)$type, "#377EB8", "#E41A1C")

# Layout
layout_coords <- matrix(0, nrow = igraph::vcount(g_bip2), ncol = 2)
user_nodes <- which(!igraph::V(g_bip2)$type)
movie_nodes <- which(igraph::V(g_bip2)$type)

layout_coords[user_nodes, 1] <- 0
layout_coords[user_nodes, 2] <- seq(length(user_nodes), 1, length.out = length(user_nodes))
layout_coords[movie_nodes, 1] <- 1.5
layout_coords[movie_nodes, 2] <- seq(length(movie_nodes), 1, length.out = length(movie_nodes))

plot(g_bip2,
     layout = layout_coords,
     vertex.size = 15,
     vertex.label.cex = 0.8,
     vertex.label.color = "black",
     vertex.label.dist = ifelse(igraph::V(g_bip2)$type, 2, -2),
     edge.color = edge_colors,
     edge.width = edge_widths,
     main = "")
```

## From Structure to Prediction

**Understanding**: The projected graph reveals user clusters—groups with similar taste.

. . .

**Prediction**: Recommendations come from highly-connected neighbors in this similarity graph.

. . .

**The insight**: Recommendation is fundamentally about **graph structure**. Collaborative filtering asks: "What do my graph neighbors like that I haven't seen?"

# Example 3: LearningGraph

## Knowledge Graphs

A **knowledge graph** represents structured knowledge:

- **Nodes** have types (Person, Skill, Course, Work-Role)
- **Edges** have labels (has_skill, requires, teaches)
- **Properties** attach to edges (proficiency level)

. . .

This is richer than a simple network: it encodes **semantics**.

## The LearningGraph

```{r}
#| label: tbl-lg-structure
#| tbl-cap: "LearningGraph structure"

# Derive structure summary from learning_graph dynamically
lg_summarize_structure <- function(lg) {
  # Count nodes by type
  node_counts <- c(
    Learner = nrow(lg$nodes$learners),
    Skill = nrow(lg$nodes$skills),
    `Work Role` = nrow(lg$nodes$work_roles),
    Course = nrow(lg$nodes$courses),
    Competency = nrow(lg$nodes$competencies)
  )
  
  # Edge type descriptions
  edge_info <- c(
    "has_skill (learner → skill)",
    "requires_skill (role → skill)",
    "prerequisite (skill → skill)",
    "teaches (course → skill)",
    "skill_in_competency (skill → competency)"
  )
  
  # Build display strings
  node_strings <- paste0(names(node_counts), " (", node_counts, ")")
  
  tibble::tibble(
    `Node Types` = node_strings,
    `Edge Types` = edge_info
  )
}

lg_summarize_structure(learning_graph) |> knitr::kable()
```

Based on the IC Data Science Competency Resource Guide (2023).

Inspired by Workera.ai's skills-intelligence platform.

## The Schema

```{r}
#| label: tbl-lg-schema
#| tbl-cap: "LearningGraph edge schema"

lg_schema <- tibble::tribble(
  ~"Edge Type", ~"Source", ~"Target", ~"Property", ~"Semantics",
  "has_skill", "learner", "skill", "proficiency", "current level",
  "requires_skill", "work_role", "skill", "proficiency", "minimum threshold",
  "prerequisite", "skill", "skill", "—", "conceptual dependency",
  "teaches", "course", "skill", "proficiency", "maximum ceiling"
)

lg_schema |> knitr::kable()
```

The schema defines what assertions are well-formed—enabling both validation and inference.

## Skill Prerequisites as a DAG

```{r}
#| label: fig-lg-prerequisite
#| fig-cap: "Skills dependent on prerequisite skills, a Directed Acyclic Graph (DAG). Note: Courses _teach_ these skills but may bundle them differently."
#| fig-height: 5

# Build prerequisite graph from eda4mldata
data(learning_graph)

prereq_edges <- 
  learning_graph$edges$prerequisite |>
  dplyr::left_join(
    y  = learning_graph$nodes$skills |> 
      dplyr::select(skill_id, skill_name),
    by = c("skill_from_id" = "skill_id")) |> 
  dplyr::rename(from = skill_name) |> 
  dplyr::left_join(
    y = learning_graph$nodes$skills |> 
      dplyr::select(skill_id, skill_name), 
    by = c("skill_to_id" = "skill_id")) |>
  dplyr::rename(to = skill_name) |>
  dplyr::select(from, to)

g_prereq <- igraph::graph_from_data_frame(prereq_edges, directed = TRUE)

# Color by competency
skill_cmp <- learning_graph$nodes$skills |>
  dplyr::select(skill_name, cmp_id)
cmp_colors <- c("#E41A1C", "#377EB8", "#4DAF4A", "#984EA3", 
                "#FF7F00", "#A65628", "#F781BF")
igraph::V(g_prereq)$color <- cmp_colors[skill_cmp$cmp_id[match(igraph::V(g_prereq)$name, skill_cmp$skill_name)]]
igraph::V(g_prereq)$size <- 12

set.seed(42)
plot(g_prereq,
     layout = igraph::layout_with_sugiyama(g_prereq)$layout,
     vertex.label.cex = 0.6,
     vertex.label.color = "black",
     edge.arrow.size = 0.4,
     edge.color = "gray50",
     main = "")
```

Entry point skills: Programming, Data Collection, Probability Theory, Linear Algebra

## Gap Analysis

**Question**: What skills does Alice need to become a Data Scientist?

```{r}
#| label: tbl-alice-gap

# Compute Alice's gap
# Note: Proficiency data may need adjustment; see eda4mldata for updates
learner_skills <- learning_graph$edges$has_skill |>
  dplyr::filter(learner_id == 1) |>  # Alice
  dplyr::select(skill_id, current = proficiency)

role_req <- learning_graph$edges$requires_skill |>
  dplyr::filter(role_id == 2) |>  # Data Scientist
  dplyr::select(skill_id, required = required_proficiency)

gap <- role_req |>
  dplyr::left_join(learner_skills, by = "skill_id") |>
  dplyr::mutate(
    current = tidyr::replace_na(current, 0L),
    gap = required - current
  ) |>
  dplyr::left_join(
    learning_graph$nodes$skills |> dplyr::select(skill_id, skill_name),
    by = "skill_id"
  ) |>
  dplyr::select(Skill = skill_name, Current = current, Required = required, Gap = gap) |>
  dplyr::arrange(dplyr::desc(Gap)) |>
  head(8)

gap |> knitr::kable()
```

## Learning Paths: From Profile to Goal

A learning path isn't simply a route from one skill to another.

. . .

Realistically, it's a path from a learner's *current skill profile* to a *target skill profile*.

. . .

**Alice's question**: Given everything I already know, what's the shortest path to Statistical Learning?

```{r}
#| label: alice-current-profile

# Show Alice's current skills (as a table for clarity)
alice_skills <- learning_graph$edges$has_skill |>
  dplyr::filter(learner_id == 1) |>
  dplyr::left_join(
    learning_graph$nodes$skills |> dplyr::select(skill_id, skill_name),
    by = "skill_id"
  ) |>
  dplyr::select(Skill = skill_name, Proficiency = proficiency) |>
  dplyr::arrange(Skill)

alice_skills |> knitr::kable()
```

## Computing the Learning Path

```{r}
#| label: learning-path-from-profile

# Find Alice's path to Statistical Learning
path <- lg_learning_path(learning_graph, 
                         learner_id = 1, 
                         target_skill = "Statistical Learning")

cat("Skills Alice must acquire:\n")
cat(paste(seq_along(path), path, sep = ". ", collapse = "\n"))
```

. . .

The algorithm finds all *missing prerequisite skills* and returns them in a valid learning order.

## Why This Isn't Exponentially Complex

**Concern**: "There are too many possible skill profiles!"
  
. . .

**Resolution**: We don't search profile space—we search the prerequisite DAG.

. . .

| Approach | Search Space | Complexity |
|----------|--------------|------------|
| All profiles | $2^{|skills|}$ | Exponential |
| DAG from current profile | Ancestors of target | $O(V + E)$ |

. . .

Alice's profile defines her *frontier*, the skills adjacent to her current skill profile. We only traverse from there to the target.

## Visualizing the Path

```{r}
#| label: fig-learning-path-viz
#| fig-cap: "Alice's learning path to Statistical Learning"
#| fig-height: 5

lg_plot_learning_path(learning_graph, 
                      learner_id = 1, 
                      target_skill = "Statistical Learning")
```

Green = skills Alice has. Red = skills to acquire. Purple = target.

## Different Profiles, Different Paths

```{r}
#| label: tbl-compare-paths
#| tbl-cap: "Learning paths vary by starting profile"

# Compare paths for different learners
comparison <- lg_compare_paths(learning_graph, 
                               learner_ids = 1:4, 
                               target_skill = "Statistical Learning")

comparison |>
  dplyr::mutate(
    path_display = purrr::map_chr(path, ~paste(.x, collapse = " → "))
  ) |>
  dplyr::select(Learner = learner_name, `Steps Required` = path_length) |>
  knitr::kable()
```

. . .

**Key insight**: Learning paths are properties of *learner-skill pairs*, not skills alone.

. . .

The DAG of prerequisite skills is fixed; the learner's position on it varies. _The_ path to Statistical Learning doesn't exist—only Alice's path, Bob's path, Carol's path.

## The Algorithm

```r
lg_learning_path <- function(lg, learner_id, target_skill) {
 
  # 1. Get learner's current skills
  current <- get_learner_skills(lg, learner_id)
 
  # 2. Find all ancestors of target (transitive prerequisites)
  ancestors <- igraph::subcomponent(prereq_graph, target, mode = "in")
 
  # 3. Filter to skills learner doesn't have
  missing <- setdiff(ancestors, current)
 
  # 4. Return in topological order (valid learning sequence)
  igraph::topo_sort(igraph::induced_subgraph(missing))
}
```

This is **graph reachability**, not combinatorial search.

## Real-World Application: Workera

This isn't hypothetical. Companies like **Workera** (co-founded by Kian Katanforoosh, with Andrew Ng as chairman) have built businesses on exactly this structure.

. . .

| Workera Capability | Graph Interpretation |
|--------------------|---------------------|
| 3,000+ micro-skills | Fine-grained skill nodes |
| Personalized learning paths | Shortest path through prerequisites |
| Skill gap assessment | Compare current vs. required subgraphs |
| "Sage" AI mentor | LLM grounded by knowledge graph |

## The Dual Perspective Again

**Understanding**: The knowledge graph encodes domain expertise—what skills exist, how they relate, and the work-roles that require them.

. . .

**Prediction/Decision Support**: Given where a learner is, what should they learn next? What's the most efficient path to their goal?

. . .

This *knowledge graph* goes beyond storing knowledge; it enables reasoning about learning paths.

. . .

With these examples as motivation, we now turn to the formal concepts underlying graph analysis.

# Fundamental Concepts

## Nodes and Edges

A **graph** $G = (V, E)$ consists of:

- $V$ = set of **vertices** (nodes)
- $E$ = set of **edges** (connections between nodes)

. . .

**Undirected**: Edge $\{u, v\}$ is symmetric (friendship)

**Directed**: Edge $(u, v)$ has direction (follows, links to)

. . .

**Weighted**: Edges carry numerical values (distance, strength)

**Labeled**: Edges have types (prerequisite, teaches, knows)

## Matrix Representations

The **adjacency matrix** $A$ encodes connections:

$$A_{ij} = \begin{cases} 1 & \text{if edge } (i,j) \in E \\ 0 & \text{otherwise} \end{cases}$$

. . .

The **degree matrix** $D$ is diagonal:

$$D_{ii} = \sum_j A_{ij} = \text{degree of node } i$$

. . .

The **Laplacian** $L = D - A$ has deep connections to graph structure.

## Paths and Connectivity

A **path** is a sequence of edges connecting two nodes.

. . .

**Shortest path**: The path with minimum total weight (or fewest edges).

. . .

A graph is **connected** if a path exists between every pair of nodes.

**Connected components**: Maximal connected subgraphs.

. . .

A **directed acyclic graph (DAG)** has no cycles—crucial for prerequisite structures.

# Measuring Importance

## Centrality: Who Matters?

Different questions → different centrality measures:

| Measure | Question | Karate Club Leader |
|---------|----------|-------------------|
| **Degree** | Who has the most connections? | Mr. Hi |
| **Betweenness** | Who controls information flow? | Mr. Hi |
| **Closeness** | Who can reach everyone quickly? | Central members |
| **PageRank** | Who is endorsed by important others? | Both leaders |

## Betweenness Centrality

$$\gamma(v) = \sum_{s \neq v \neq t} \frac{\sigma_{st}(v)}{\sigma_{st}}$$

where $\sigma_{st}$ = number of shortest paths from $s$ to $t$

and $\sigma_{st}(v)$ = number of those paths passing through $v$

. . .

**Interpretation**: Nodes with high betweenness are **bridges**—removing them fragments the network.

## PageRank

Originally for ranking web pages. The idea:

. . .

A page is important if important pages link to it.

. . .

**Random surfer model**: Follow links randomly, occasionally jump to a random page. PageRank = long-run fraction of time at each node.

. . .

$$\text{PR}(v) = \frac{1-d}{N} + d \sum_{u \to v} \frac{\text{PR}(u)}{\text{out-degree}(u)}$$

where $d \approx 0.85$ is the damping factor, and out-degree counts out-going edges.

# Finding Structure

## Communities

A **community** is a group of nodes more densely connected internally than externally.

. . .

**Modularity** $Q$ measures community quality by comparing actual edges to expectation:

$$Q = \frac{1}{2m} \sum_{ij} \left[ A_{ij} - \frac{k_i k_j}{2m} \right] \delta(c_i, c_j)$$

where $m$ = total edges, $k_i$ = degree of node $i$, and $\delta(c_i, c_j) = 1$ if $i, j$ share a community.

. . .

$Q > 0.3$ typically indicates significant community structure.

## Community Detection Algorithms

| Algorithm | Approach | Complexity |
|-----------|----------|------------|
| **Girvan-Newman** | Iteratively remove high-betweenness edges | Slow, interpretable |
| **Louvain** | Greedily optimize modularity | Fast, widely used |
| **Spectral** | Eigenvectors of Laplacian | Principled; minimizes edges between groups |
| **Leiden** | Improved Louvain, allows overlaps | State of the art |

. . .

No single "best" algorithm—choice depends on graph size, structure, and goals.

## Spectral Clustering Intuition

The **graph Laplacian** $L = D - A$ encodes connectivity.

. . .

Its **eigenvectors** reveal structure:

- First eigenvector: constant (trivial)
- Second eigenvector: signs indicate two-way partition
- More eigenvectors: finer partitions

. . .

**Fiedler vector** (second eigenvector) provides a principled way to split a graph.

# Graphs and Machine Learning

## Graphs as Feature Sources

Traditional ML on graphs: extract features, then apply standard ML methods to features.

. . .

**Node features**:

- Degree, centrality measures
- Community membership
- Local clustering coefficient

. . .

**Graph features**:

- Density, diameter
- Degree distribution
- Modularity

## Link Prediction

**Question**: Which pairs of unconnected nodes will connect in the future?

. . .

**Common neighbors**: $|N(u) \cap N(v)|$

**Jaccard coefficient**: $\frac{|N(u) \cap N(v)|}{|N(u) \cup N(v)|}$

**Adamic-Adar**: $\sum_{w \in N(u) \cap N(v)} \frac{1}{\log |N(w)|}$

. . .

These are *graph-derived features* for a classification problem.

## GNN: Graph Neural Networks (Brief)

Modern approach: learn node representations directly from graph structure.

. . .

**Message passing**: Nodes aggregate information from neighbors, iteratively.

. . .

$$h_v^{(k+1)} = \text{UPDATE}\left(h_v^{(k)}, \text{AGGREGATE}\left(\{h_u^{(k)} : u \in N(v)\}\right)\right)$$

. . .

GNNs can learn features automatically—but require substantial data and compute.

For many problems, classical graph features be preferred: easier to interpret, and less compute-intensive.

# The Dual Perspectives Revisited

## Structure Enables Both Goals

| Perspective | Methods | Questions |
|-------------|---------|-----------|
| **Understanding** | Centrality, communities, components | Who matters? What groups exist? How does information flow? |
| **Prediction** | Link prediction, recommendation, node classification | What will happen? What should we recommend? |

. . .

The same graph structure serves both: **understanding why** and **predicting what**.

## From Social to Semantic

Our three examples show increasing semantic richness:

| Example | Nodes | Edges | Semantics |
|---------|-------|-------|-----------|
| Karate Club | People | Interacts | Homogeneous |
| MovieLens | Users, Movies | Rates | Bipartite, weighted |
| LearningGraph | Learners, Skills, Roles, Courses | Multiple types | Knowledge graph |

. . .

Richer semantics → richer reasoning, but also more complex modeling.

## Key Takeaways

1. **Graphs encode relationships**—and relationships are information.

2. **Structure reveals mechanism**—communities exist because of homophily; centrality reflects influence pathways.

3. **The same structure serves prediction and understanding**—predicting future connections exploits the patterns that community detection reveals.

4. **Knowledge graphs add semantics**—typed nodes and labeled edges enable richer queries and reasoning.

# Summary and Resources

## What We Covered

- **Three examples**: Karate Club, MovieLens, LearningGraph
- **Fundamental concepts**: Nodes, edges, matrices, paths
- **Centrality measures**: Degree, betweenness, PageRank
- **Community detection**: Modularity, Louvain, spectral methods
- **ML connections**: Graph-derived features, predicting new edges, GNNs

## Key R Packages

| Package | Purpose |
|---------|---------|
| `igraph` | Graph creation, algorithms, analysis |
| `tidygraph` | Tidy interface to igraph |
| `ggraph` | ggplot2-style visualization |
| `igraphdata` | Built-in datasets |

## Resources

**Textbooks**:

- Newman, *Networks* (2nd ed., 2018) — comprehensive reference
- Barabási, *Network Science* (2016) — free online, beautifully illustrated
- Easley & Kleinberg, *Networks, Crowds, and Markets* (2010) — interdisciplinary

**Tutorial**:

- Ognyanova, "Network Visualization with R" (kateto.net)

## Exercises

1. Load the Karate Club graph and verify that Louvain recovers the factional split.

2. Compute the betweenness centrality of all nodes. Which node has the highest betweenness? Why does this make sense sociologically?

3. Using the LearningGraph, find Alice's learning path to Problem Formulation. What does this path suggest about skill development?

4. Create a bipartite graph from a small subset of MovieLens data. Project it onto users and identify clusters of similar users.

5. For the prerequisite DAG in LearningGraph, verify that it is acyclic. What would a cycle mean pedagogically?
